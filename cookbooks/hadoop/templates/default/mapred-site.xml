<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <% if @job_tracker %>
  <property>
    <name>mapred.job.tracker</name>
    <value><%= @job_tracker[:ipaddress] %>:9001</value>
  </property>
  <% end %>

  <property>
    <name>mapred.jobtracker.taskScheduler</name>
    <value>org.apache.hadoop.mapred.FairScheduler</value>
  </property>

  <property>
    <name>mapred.fairscheduler.preemption</name>
    <value>true</value>
  </property>

  <!-- http://hadoop.apache.org/docs/r1.0.1/cluster_setup.html#Configuring+the+Hadoop+Daemons -->
  <property>
    <name>mapred.task.tracker.task-controller</name>
    <value>org.apache.hadoop.mapred.DefaultTaskController</value>
  </property>

  <property>
    <name>mapred.tasktracker.map.tasks.maximum</name>
    <value><%= node[:hadoop][:mapper][:tasks] %></value>
  </property>

  <property>
    <name>mapred.tasktracker.reduce.tasks.maximum</name>
    <value><%= node[:hadoop][:reducer][:tasks] %></value>
  </property>

  <property>
    <name>mapred.max.tracker.failures</name>
    <value>20</value>
  </property>

  <property>
    <name>mapred.child.java.opts</name>
    <value>-Duser.timezone=UTC -Dfile.encoding=UTF-8 -Xmx4g -Djava.io.tmpdir=<%= node[:hadoop][:java_tmp] %></value>
  </property>

  <property>
    <name>mapred.map.tasks.speculative.execution</name>
    <value>false</value>
  </property>

  <property>
    <name>mapred.reduce.tasks.speculative.execution</name>
    <value>false</value>
  </property>

  <!-- http://stackoverflow.com/questions/2354525/what-should-be-hadoop-tmp-dir -->
  <property>
    <name>mapred.system.dir</name>
    <value>/mapred/system.<%= node.cluster_name %></value>
  </property>

  <!-- do not create /var/tmp in HDFS for staging area -->
  <property>
    <name>mapreduce.jobtracker.staging.root.dir</name>
    <value>/user</value>
  </property>

  <!-- make sure these are stored on the dedicated hadoop disks -->
  <property>
    <name>mapred.local.dir</name>
    <value><%= node[:hadoop][:tmp_dir] %>/${user.name}/mapred/local.<%= node.cluster_name %></value>
  </property>

  <!-- compression of data between the mapper and the reducer -->
  <!-- These files are not stored in hdfs, but local /var/tmp/hadoop -->
  <property>
    <name>mapred.compress.map.output</name>
    <value>true</value>
  </property>

  <property>
    <name>mapred.output.compression.type</name>
    <value>BLOCK</value>
  </property>
  <property>
    <name>mapred.output.compression.codec</name>
    <value>org.apache.hadoop.io.compress.GzipCodec</value>
  </property>
  <property>
    <name>mapred.map.output.compression.codec</name>
    <value>org.apache.hadoop.io.compress.GzipCodec</value>
    <!-- <value>org.apache.hadoop.io.compress.SnappyCodec</value> -->
  </property>


  <property>
    <name>io.sort.factor</name>
    <value><%= node[:hadoop][:io][:sort][:factor] %></value>
  </property>

  <property>
    <name>io.sort.mb</name>
    <value><%= node[:hadoop][:io][:sort][:mb] %></value>
  </property>

  <property>
    <name>io.sort.record.percent</name>
    <!-- our currnt record size is avg 1000 bytes .. we might wanna change this in the future optimal is 16/(16+(bytes/records)) -->
    <value>0.03</value>
  </property>

  <property>
    <name>io.sort.spill.percent</name>
    <value>0.95</value>
  </property>

</configuration>
