<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
  <property>
    <name>mapreduce.tasktracker.http.address</name>
    <value>0.0.0.0:0</value>
  </property>
  <property>
    <name>mapreduce.jobtracker.http.address</name>
    <value>0.0.0.0:0</value>
  </property>
  <% if hadoop2_historyserver %>
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value><%= hadoop2_historyserver[:fqdn] %>:10020</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value><%= hadoop2_historyserver[:fqdn] %>:19888</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.recovery.enable</name>
    <value>true</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.recovery.store.class</name>
    <value>org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.recovery.store.fs.uri</name>
    <value>file://${hadoop.tmp.dir}/mapred-jobhistory-state</value>
  </property>
  <% end %>
  <property>
    <name>mapreduce.client.submit.file.replication</name>
    <value><%= [hadoop2_datanodes.length, 10].min %></value>
  </property>
  <property>
    <name>mapreduce.job.maps</name>
    <value>32</value>
  </property>
  <property>
    <name>mapreduce.job.reduces</name>
    <value>32</value>
  </property>
  <property>
    <name>mapreduce.map.speculative</name>
    <value>false</value>
  </property>
  <property>
    <name>mapreduce.map.cpu.vcores</name>
    <value>1</value>
  </property>
  <property>
    <name>mapreduce.map.memory.mb</name>
    <value><%= (node[:hadoop2][:yarn][:mem_per_container] * 1024).to_i %></value>
  </property>
  <property>
    <name>mapreduce.map.java.opts</name>
    <value>-Xmx<%= (0.8 * node[:hadoop2][:yarn][:mem_per_container] * 1024).to_i %>m -server -XX:+UseConcMarkSweepGC -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=<%= node[:hadoop2][:java_tmp] %></value>
  </property>
  <property>
    <name>mapreduce.reduce.speculative</name>
    <value>false</value>
  </property>
  <property>
    <name>mapreduce.reduce.cpu.vcores</name>
    <value>1</value>
  </property>
  <property>
    <name>mapreduce.reduce.memory.mb</name>
    <value><%= (node[:hadoop2][:yarn][:mem_per_container] * 1024).to_i %></value>
  </property>
  <property>
    <name>mapreduce.reduce.java.opts</name>
    <value>-Xmx<%= (0.8 * 2 * node[:hadoop2][:yarn][:mem_per_container] * 1024).to_i %>m -server -XX:+UseConcMarkSweepGC -Duser.timezone=UTC -Dfile.encoding=UTF-8 -Djava.io.tmpdir=<%= node[:hadoop2][:java_tmp] %></value>
  </property>
  <property>
    <name>mapreduce.reduce.shuffle.parallelcopies</name>
    <value>50</value>
  </property>
  <property>
    <name>mapreduce.task.io.sort.mb</name>
    <value>256</value>
  </property>
  <property>
    <name>mapreduce.task.io.sort.factor</name>
    <value>20</value>
  </property>
  <property>
    <name>mapreduce.task.timeout</name>
    <value>1800000</value>
  </property>
  <!-- Compression -->
  <property>
    <name>mapreduce.output.fileoutputformat.compress</name>
    <value>false</value>
  </property>
  <property>
    <name>mapreduce.map.output.compress</name>
    <value>true</value>
  </property>
  <property>
    <name>mapreduce.output.fileoutputformat.compress.type</name>
    <value>BLOCK</value>
  </property>
  <property>
    <name>mapreduce.map.output.compress.codec</name>
    <value>org.apache.hadoop.io.compress.Lz4Codec</value>
  </property>
  <property>
    <name>mapreduce.output.fileoutputformat.compress.codec</name>
    <value>org.apache.hadoop.io.compress.GzipCodec</value>
  </property>
</configuration>
